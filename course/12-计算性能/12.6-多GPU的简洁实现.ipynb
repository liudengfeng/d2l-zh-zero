{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fe96bfa",
   "metadata": {},
   "source": [
    "# 12.6 多GPU的简洁实现\n",
    "\n",
    "每个新模型的并行计算都从零开始实现是无趣的。此外，优化同步工具以获得高性能也是有好处的。下面我们将展示如何使用深度学习框架的高级API来实现这一点。数学和算法与 12.5中的相同。本节的代码至少需要两个GPU来运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3f8c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 获取当前 Notebook 文件的路径\n",
    "notebook_path = os.path.abspath(\".\")\n",
    "\n",
    "# 获取父级目录的路径\n",
    "parent_directory = os.path.dirname(notebook_path)\n",
    "\n",
    "# 将父级目录添加到 sys.path\n",
    "if parent_directory not in sys.path:\n",
    "    sys.path.append(parent_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f523f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tab pytorch\n",
    "import d2l\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77e60d0",
   "metadata": {},
   "source": [
    "## [**简单网络**]\n",
    "\n",
    "让我们使用一个比 12.5的LeNet更有意义的网络，它依然能够容易地和快速地训练。我们选择的是 :cite:`He.Zhang.Ren.ea.2016`中的ResNet-18。因为输入的图像很小，所以稍微修改了一下。与 7.6节的区别在于，我们在开始时使用了更小的卷积核、步长和填充，而且删除了最大汇聚层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc04ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tab pytorch\n",
    "#@save\n",
    "def resnet18(num_classes, in_channels=1):\n",
    "    \"\"\"稍加修改的ResNet-18模型\"\"\"\n",
    "    def resnet_block(in_channels, out_channels, num_residuals,\n",
    "                     first_block=False):\n",
    "        blk = []\n",
    "        for i in range(num_residuals):\n",
    "            if i == 0 and not first_block:\n",
    "                blk.append(d2l.Residual(in_channels, out_channels,\n",
    "                                        use_1x1conv=True, strides=2))\n",
    "            else:\n",
    "                blk.append(d2l.Residual(out_channels, out_channels))\n",
    "        return nn.Sequential(*blk)\n",
    "\n",
    "    # 该模型使用了更小的卷积核、步长和填充，而且删除了最大汇聚层\n",
    "    net = nn.Sequential(\n",
    "        nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU())\n",
    "    net.add_module(\"resnet_block1\", resnet_block(\n",
    "        64, 64, 2, first_block=True))\n",
    "    net.add_module(\"resnet_block2\", resnet_block(64, 128, 2))\n",
    "    net.add_module(\"resnet_block3\", resnet_block(128, 256, 2))\n",
    "    net.add_module(\"resnet_block4\", resnet_block(256, 512, 2))\n",
    "    net.add_module(\"global_avg_pool\", nn.AdaptiveAvgPool2d((1,1)))\n",
    "    net.add_module(\"fc\", nn.Sequential(nn.Flatten(),\n",
    "                                       nn.Linear(512, num_classes)))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0b5559",
   "metadata": {},
   "source": [
    "## 网络初始化\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "我们将在训练回路中初始化网络。请参见 4.8复习初始化方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05df2d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tab pytorch\n",
    "net = resnet18(10)\n",
    "# 获取GPU列表\n",
    "devices = d2l.try_all_gpus()\n",
    "# 我们将在训练代码实现中初始化网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21d4b36",
   "metadata": {},
   "source": [
    "## [**训练**]\n",
    "\n",
    "如前所述，用于训练的代码需要执行几个基本功能才能实现高效并行：\n",
    "\n",
    "* 需要在所有设备上初始化网络参数；\n",
    "* 在数据集上迭代时，要将小批量数据分配到所有设备上；\n",
    "* 跨设备并行计算损失及其梯度；\n",
    "* 聚合梯度，并相应地更新参数。\n",
    "\n",
    "最后，并行地计算精确度和发布网络的最终性能。除了需要拆分和聚合数据外，训练代码与前几章的实现非常相似。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7aab0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tab pytorch\n",
    "def train(net, num_gpus, batch_size, lr):\n",
    "    train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
    "    devices = [d2l.try_gpu(i) for i in range(num_gpus)]\n",
    "    def init_weights(m):\n",
    "        if type(m) in [nn.Linear, nn.Conv2d]:\n",
    "            nn.init.normal_(m.weight, std=0.01)\n",
    "    net.apply(init_weights)\n",
    "    # 在多个GPU上设置模型\n",
    "    net = nn.DataParallel(net, device_ids=devices)\n",
    "    trainer = torch.optim.SGD(net.parameters(), lr)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    timer, num_epochs = d2l.Timer(), 10\n",
    "    animator = d2l.Animator('epoch', 'test acc', xlim=[1, num_epochs])\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        timer.start()\n",
    "        for X, y in train_iter:\n",
    "            trainer.zero_grad()\n",
    "            X, y = X.to(devices[0]), y.to(devices[0])\n",
    "            l = loss(net(X), y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "        timer.stop()\n",
    "        animator.add(epoch + 1, (d2l.evaluate_accuracy_gpu(net, test_iter),))\n",
    "    print(f'测试精度：{animator.Y[0][-1]:.2f}，{timer.avg():.1f}秒/轮，'\n",
    "          f'在{str(devices)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddeb08f4",
   "metadata": {},
   "source": [
    "接下来看看这在实践中是如何运作的。我们先[**在单个GPU上训练网络**]进行预热。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2188595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tab pytorch, paddle\n",
    "train(net, num_gpus=1, batch_size=256, lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09f3c20",
   "metadata": {},
   "source": [
    "接下来我们[**使用2个GPU进行训练**]。与 12.5中评估的LeNet相比，ResNet-18的模型要复杂得多。这就是显示并行化优势的地方，计算所需时间明显大于同步参数需要的时间。因为并行化开销的相关性较小，因此这种操作提高了模型的可伸缩性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f976f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tab pytorch\n",
    "train(net, num_gpus=2, batch_size=512, lr=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c870aa7",
   "metadata": {},
   "source": [
    "## 小结\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 练习\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[Discussions](https://discuss.d2l.ai/t/2803)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
